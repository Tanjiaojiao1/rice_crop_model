{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset =pd.read_excel('.../data/RFdata.xlsx')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset1=dataset.dropna(axis='index', how='any',subset=['phothermalerro_rev-til'])\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset1.iloc[:, [54]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.iloc[:, [2,3,4,11,12,13,14,15,16]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training Data\n",
    "# Independent Variable ：latitude,longitude,altitude,average daily temperature, average maximum temperature, average minimum temperature,\n",
    "#                       average sun shine hour, average rainfall, high temperature stress/low temperature damage days\n",
    "# Dependent Variable：error days\n",
    "x = dataset1.iloc[: , [2,3,4,11,12,13,14,15,16]].values\n",
    "y = dataset1.iloc[:, 54].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is divided into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "print(x_train.shape)#View the amount of training set data\n",
    "print(x_test.shape)#View the amount of test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Mean e3Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:',np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "train_pred = regressor.predict(x_train)\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators =[int(x) for x in np.linspace(200, 500, 150)]\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 20, 11)]\n",
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']\n",
    "# Criterion to split on\n",
    "rf_criterion = ['mse', 'mae']\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]\n",
    "rf_random_state = [0,42]\n",
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators, 'max_depth': rf_max_depth, 'max_features': rf_max_features, 'criterion': rf_criterion,\n",
    "           'min_samples_split': rf_min_samples_split, 'min_impurity_decrease': rf_min_impurity_decrease, 'bootstrap': rf_bootstrap,\n",
    "           'random_state': rf_random_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create the model to be tuned\n",
    "rf_base = RandomForestRegressor()\n",
    "# Create the random search Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
    "                               n_iter = 200, cv = 3, verbose = 2, random_state = 0, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "# View the best parameters from the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Create the final Multiple Linear Regression\n",
    "mlr_final = LinearRegression()\n",
    "# Create the final Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators = 258, min_samples_split = 6, min_impurity_decrease = 0.0, \n",
    "                                 max_features = 'sqrt', max_depth = 5,  criterion = 'mse',\n",
    "                                 bootstrap = True, random_state =42)\n",
    "# Train the models using 70% of the original data\n",
    "mlr_final.fit(x_train, y_train)\n",
    "rf_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = rf_final.predict(x_train)\n",
    "metrics.r2_score(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred =  rf_final.predict(x_test)\n",
    "mse_test = metrics.mean_squared_error(y_test,test_pred)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function that compares all final models\n",
    "def final_comparison(models, test_features, test_labels):    \n",
    "    scores = pd.DataFrame()    \n",
    "    for model in models:        \n",
    "        predictions = model.predict(test_features)     \n",
    "        mae = round(metrics.mean_absolute_error(test_labels, predictions), 4)        \n",
    "        mse = round(metrics.mean_squared_error(test_labels, predictions), 4)        \n",
    "        r2 = round(metrics.r2_score(test_labels, predictions), 4)        \n",
    "        errors = abs(predictions - test_labels) \n",
    "        test_labels[test_labels==0]=1\n",
    "        mape = 100 * np.mean(errors /test_labels)        \n",
    "        accuracy = round(100 - mape, 4)        \n",
    "        scores[str(model)] = [mae, mse, r2, accuracy]    \n",
    "        scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the comparison function with the three final models\n",
    "final_scores = final_comparison([mlr_final,rf_final], x_test, y_test)  #regressor / rf_final\n",
    "# Adjust the column headers\n",
    "final_scores.columns  = ['Linear Regression', 'Random Forest']\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get numerical feature importances\n",
    "importances = list(rf_final.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "print(importances)\n",
    "# Saving feature names for later use\n",
    "# feature_list = list(dataset.columns)[2:23]\n",
    "feature_list = ['lat','lon','alt','MeanTmax_Rev-Til','MeanTmin_Rev-Til','MeanTave_Rev-Til',\n",
    "                'MeanSunhours_Rev-Til','MeanRain_Rev-Til','MeanHumidity_Rev-Til']\n",
    "\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "# Set the style\n",
    "# plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(10, 6))\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list,rotation=90,fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance',fontsize=15); plt.xlabel('Variable',fontsize=15); plt.title('Variable Importances',fontsize=15);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
